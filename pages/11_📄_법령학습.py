"""ğŸ“„ ë²•ë ¹ í•™ìŠµ"""
import streamlit as st
PAGE_DIR = os.path.dirname(os.path.abspath(__file__))
APP_DIR = os.path.dirname(PAGE_DIR)
if APP_DIR not in sys.path:
    sys.path.insert(0, APP_DIR)
import sys, os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from data.label_engine import *

# page_config set in main app.py
st.markdown("# ğŸ“„ ë²•ë ¹ PDF í•™ìŠµ")
st.markdown("3ê°œ ë²•ë ¹ PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ì§€ì‹ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤")
st.markdown("---")

for doc_key, schema in REGULATION_SCHEMA.items():
    with st.container(border=True):
        c1, c2 = st.columns([2, 3])

        with c1:
            kb = load_knowledge(doc_key)
            st.markdown(f"### {'âœ…' if kb else 'â¬œ'} {schema['ë²•ë ¹ëª…']}")
            st.caption(f"ì•½ì¹­: {schema['ì•½ì¹­']} | ê²€í† í•­ëª©: {len(schema['ê²€í† í•­ëª©'])}ê°œ")

            if kb:
                st.success(f"í•™ìŠµ ì™„ë£Œ: {len(kb['chunks'])}ê°œ ì²­í¬, {kb['full_text_length']:,}ì")
                st.caption(f"íŒŒì¼: {kb['filename']} | ê°±ì‹ : {kb['updated'][:16]}")

                if st.button(f"ğŸ—‘ï¸ ì´ˆê¸°í™”", key=f"reset_{doc_key}"):
                    filepath = os.path.join(KB_DIR, f"{doc_key}.json")
                    if os.path.exists(filepath):
                        os.remove(filepath)
                    st.rerun()

        with c2:
            uploaded = st.file_uploader(
                f"{schema['ì•½ì¹­']} PDF ì—…ë¡œë“œ",
                type=["pdf"], key=f"pdf_{doc_key}",
                help=f"{schema['ë²•ë ¹ëª…']} ì›ë¬¸ PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”"
            )

            if uploaded:
                with st.spinner(f"ğŸ“„ {uploaded.name} ì²˜ë¦¬ ì¤‘..."):
                    text, msg = extract_pdf(uploaded)

                if text:
                    n_chunks = save_knowledge(doc_key, text, uploaded.name)
                    st.success(f"âœ… {msg} â†’ {n_chunks}ê°œ ì¡°í•­ ì²­í¬ë¡œ ì €ì¥")

                    with st.expander("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°", expanded=False):
                        st.text_area("", text[:3000], height=200, key=f"preview_{doc_key}")
                        if len(text) > 3000:
                            st.caption(f"(ì „ì²´ {len(text):,}ì ì¤‘ ìƒìœ„ 3,000ì)")
                    st.rerun()
                else:
                    st.error(f"âŒ {msg}")

    st.markdown("")

# ì „ì²´ í˜„í™© ìš”ì•½
st.markdown("---")
st.markdown("### ğŸ“Š ì§€ì‹ë² ì´ìŠ¤ í˜„í™©")

all_kb = load_all_knowledge()
total_chunks = sum(len(kb.get("chunks", [])) for kb in all_kb.values())
total_chars = sum(kb.get("full_text_length", 0) for kb in all_kb.values())

mc1, mc2, mc3 = st.columns(3)
mc1.metric("í•™ìŠµ ë²•ë ¹", f"{len(all_kb)}/3")
mc2.metric("ì´ ì²­í¬", f"{total_chunks}ê°œ")
mc3.metric("ì´ í…ìŠ¤íŠ¸", f"{total_chars:,}ì")

if len(all_kb) == 3:
    st.success("ğŸ‰ 3ê°œ ë²•ë ¹ ëª¨ë‘ í•™ìŠµ ì™„ë£Œ! [ğŸ” ì ë¶€íŒì •] í˜ì´ì§€ì—ì„œ ê²€í† ë¥¼ ì‹œì‘í•˜ì„¸ìš”.")
elif len(all_kb) > 0:
    missing = [s["ì•½ì¹­"] for k, s in REGULATION_SCHEMA.items() if k not in all_kb]
    st.warning(f"âš ï¸ ë¯¸í•™ìŠµ: {', '.join(missing)} â€” PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”. (í•™ìŠµ ì—†ì´ë„ ê¸°ë³¸ ê·œì¹™ ê¸°ë°˜ íŒì •ì€ ê°€ëŠ¥í•©ë‹ˆë‹¤)")
else:
    st.info("ğŸ“¤ ë²•ë ¹ PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ AIê°€ ë” ì •í™•í•˜ê²Œ íŒì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. PDF ì—†ì´ë„ ê¸°ë³¸ íŒì •ì€ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

# ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰
st.markdown("---")
st.markdown("### ğŸ” ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰")
search_q = st.text_input("í‚¤ì›Œë“œ ê²€ìƒ‰", placeholder="ì˜ˆ: ì†Œë¹„ê¸°í•œ, ì•Œë ˆë¥´ê¸°, ì›ì‚°ì§€, ìš©ì¶œì‹œí—˜")

if search_q:
    for doc_key, schema in REGULATION_SCHEMA.items():
        results = search_knowledge(doc_key, search_q)
        if results:
            st.markdown(f"**ğŸ“– {schema['ë²•ë ¹ëª…']}** â€” {len(results)}ê±´")
            for i, r in enumerate(results[:5]):
                with st.expander(f"ê²°ê³¼ {i+1}", expanded=i < 2):
                    st.text(r[:500])

render_chatbot("ë²•ë ¹í•™ìŠµ", "ë²•ë ¹ PDF ì—…ë¡œë“œ ë° ì§€ì‹ë² ì´ìŠ¤ êµ¬ì¶• í˜ì´ì§€.")
